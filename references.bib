@article{kaplanSiriSiriMy2019,
  title = {Siri, {{Siri}}, in My Hand: {{Who}}'s the Fairest in the Land? {{On}} the Interpretations, Illustrations, and Implications of Artificial Intelligence},
  shorttitle = {Siri, {{Siri}}, in My Hand},
  author = {Kaplan, Andreas and Haenlein, Michael},
  year = {2019},
  month = jan,
  journal = {Business Horizons},
  volume = {62},
  number = {1},
  pages = {15--25},
  issn = {0007-6813},
  doi = {10.1016/j.bushor.2018.08.004},
  urldate = {2024-01-14},
  abstract = {Artificial intelligence (AI){\textemdash}defined as a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation{\textemdash}is a topic in nearly every boardroom and at many dinner tables. Yet, despite this prominence, AI is still a surprisingly fuzzy concept and a lot of questions surrounding it are still open. In this article, we analyze how AI is different from related concepts, such as the Internet of Things and big data, and suggest that AI is not one monolithic term but instead needs to be seen in a more nuanced way. This can either be achieved by looking at AI through the lens of evolutionary stages (artificial narrow intelligence, artificial general intelligence, and artificial super intelligence) or by focusing on different types of AI systems (analytical AI, human-inspired AI, and humanized AI). Based on this classification, we show the potential and risk of AI using a series of case studies regarding universities, corporations, and governments. Finally, we present a framework that helps organizations think about the internal and external implications of AI, which we label the Three C Model of Confidence, Change, and Control.},
  keywords = {Artificial intelligence,Big data,Deep learning,Expert systems,Internet of Things,Machine learning}
}

@article{lazerParableGoogleFlu2014,
  title = {The {{Parable}} of {{Google Flu}}: {{Traps}} in {{Big Data Analysis}}},
  shorttitle = {The {{Parable}} of {{Google Flu}}},
  author = {Lazer, David and Kennedy, Ryan and King, Gary and Vespignani, Alessandro},
  year = {2014},
  month = mar,
  journal = {Science},
  volume = {343},
  number = {6176},
  pages = {1203--1205},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1248506},
  urldate = {2023-05-19}
}

@article{bakerMechanisticModelsMachine2018,
  title = {Mechanistic Models versus Machine Learning, a Fight Worth Fighting for the Biological Community?},
  author = {Baker, Ruth E. and Peña, Jose-Maria and Jayamohan, Jayaratnam and Jérusalem, Antoine},
  date = {2018-05},
  journaltitle = {Biology Letters},
  shortjournal = {Biol. Lett.},
  volume = {14},
  number = {5},
  pages = {20170660},
  issn = {1744-9561, 1744-957X},
  doi = {10.1098/rsbl.2017.0660},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsbl.2017.0660},
  urldate = {2022-12-01},
  abstract = {Ninety per cent of the world's data have been generated in the last 5 years (               Machine learning: the power and promise of computers that learn by example               . Report no. DES4702. Issued April 2017. Royal Society). A small fraction of these data is collected with the aim of validating specific hypotheses. These studies are led by the development of mechanistic models focused on the causality of input–output relationships. However, the vast majority is aimed at supporting statistical or correlation studies that bypass the need for causality and focus exclusively on prediction. Along these lines, there has been a vast increase in the use of machine learning models, in particular in the biomedical and clinical sciences, to try and keep pace with the rate of data generation. Recent successes now beg the question of whether mechanistic models are still relevant in this area. Said otherwise, why should we try to understand the mechanisms of disease progression when we can use machine learning tools to directly predict disease outcome?},
  langid = {english}
}


@article{ginsbergDetectingInfluenzaEpidemics2009,
  title = {Detecting Influenza Epidemics Using Search Engine Query Data},
  author = {Ginsberg, Jeremy and Mohebbi, Matthew H. and Patel, Rajan S. and Brammer, Lynnette and Smolinski, Mark S. and Brilliant, Larry},
  year = {2009},
  month = feb,
  journal = {Nature},
  volume = {457},
  number = {7232},
  pages = {1012--1014},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature07634},
  urldate = {2023-05-19},
  abstract = {This paper - first published on-line in November 2008 - draws on data from an early version of the Google Flu Trends search engine to estimate the levels of flu in a population. It introduces a computational model that converts raw search query data into a region-by-region real-time surveillance system that accurately estimates influenza activity with a lag of about one day - one to two weeks faster than the conventional reports published by the Centers for Disease Prevention and Control.},
  copyright = {2009 Macmillan Publishers Limited. All rights reserved},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science}
}

@article{kandulaReappraisingUtilityGoogle2019,
  title = {Reappraising the Utility of {{Google Flu Trends}}},
  author = {Kandula, Sasikiran and Shaman, Jeffrey},
  year = {2019},
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {15},
  number = {8},
  pages = {e1007258},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007258},
  urldate = {2023-05-19},
  abstract = {Estimation of influenza-like illness (ILI) using search trends activity was intended to supplement traditional surveillance systems, and was a motivation behind the development of Google Flu Trends (GFT). However, several studies have previously reported large errors in GFT estimates of ILI in the US. Following recent release of time-stamped surveillance data, which better reflects real-time operational scenarios, we reanalyzed GFT errors. Using three data sources\textemdash GFT: an archive of weekly ILI estimates from Google Flu Trends; ILIf: fully-observed ILI rates from ILINet; and, ILIp: ILI rates available in real-time based on partial reporting\textemdash five influenza seasons were analyzed and mean square errors (MSE) of GFT and ILIp as estimates of ILIf were computed. To correct GFT errors, a random forest regression model was built with ILI and GFT rates from the previous three weeks as predictors. An overall reduction in error of 44\% was observed and the errors of the corrected GFT are lower than those of ILIp. An 80\% reduction in error during 2012/13, when GFT had large errors, shows that extreme failures of GFT could have been avoided. Using autoregressive integrated moving average (ARIMA) models, one- to four-week ahead forecasts were generated with two separate data streams: ILIp alone, and with both ILIp and corrected GFT. At all forecast targets and seasons, and for all but two regions, inclusion of GFT lowered MSE. Results from two alternative error measures, mean absolute error and mean absolute proportional error, were largely consistent with results from MSE. Taken together these findings provide an error profile of GFT in the US, establish strong evidence for the adoption of search trends based 'nowcasts' in influenza forecast systems, and encourage reevaluation of the utility of this data source in diverse domains.},
  langid = {english},
  keywords = {Archives,Epidemiology,Forecasting,Infectious disease surveillance,Influenza,Mathematical functions,Outpatients,United States}
}

@article{pearlSevenToolsCausal2019,
  title = {The Seven Tools of Causal Inference, with Reflections on Machine Learning},
  author = {Pearl, Judea},
  date = {2019-02-21},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {62},
  number = {3},
  pages = {54--60},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3241036},
  url = {https://dl.acm.org/doi/10.1145/3241036},
  urldate = {2022-11-18},
  abstract = {The kind of causal inference seen in natural human thought can be "algorithmitized" to help produce human-level machine intelligence.},
  langid = {english},
  file = {/home/george/Zotero/storage/9EJUGCEF/Pearl - 2019 - The seven tools of causal inference, with reflecti.pdf}
}

@misc{nasrScalableExtractionTraining2023,
  title = {Scalable {{Extraction}} of {{Training Data}} from ({{Production}}) {{Language Models}}},
  author = {Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A. Feder and Ippolito, Daphne and {Choquette-Choo}, Christopher A. and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  year = {2023},
  month = nov,
  number = {arXiv:2311.17035},
  eprint = {2311.17035},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2311.17035},
  urldate = {2024-01-14},
  abstract = {This paper studies extractable memorization: training data that an adversary can efficiently extract by querying a machine learning model without prior knowledge of the training dataset. We show an adversary can extract gigabytes of training data from open-source language models like Pythia or GPT-Neo, semi-open models like LLaMA or Falcon, and closed models like ChatGPT. Existing techniques from the literature suffice to attack unaligned models; in order to attack the aligned ChatGPT, we develop a new divergence attack that causes the model to diverge from its chatbot-style generations and emit training data at a rate 150x higher than when behaving properly. Our methods show practical attacks can recover far more data than previously thought, and reveal that current alignment techniques do not eliminate memorization.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {/home/george/Zotero/storage/6D4GMVY5/Nasr et al. - 2023 - Scalable Extraction of Training Data from (Product.pdf;/home/george/Zotero/storage/VCJKRRSS/2311.html}
}

@misc{GenerativeAIHas,
  title = {Generative {{AI Has}} a {{Visual Plagiarism Problem}} - {{IEEE Spectrum}}},
  urldate = {2024-01-14},
  abstract = {Experiments with Midjourney and DALL-E 3 show a copyright minefield},
  howpublished = {https://spectrum.ieee.org/midjourney-copyright},
  langid = {english},
  file = {/home/george/Zotero/storage/DMBY398U/midjourney-copyright.html}
}

@misc{cnneeDiarioNewYork2023,
  title = {{El diario The New York Times demanda a OpenAI y Microsoft por infracci{\'o}n de derechos de autor}},
  author = {CNNEE},
  year = {2023},
  month = dec,
  journal = {CNN},
  urldate = {2024-01-14},
  abstract = {El diario The New York Times ha demandado a OpenAI y Microsoft por infracci{\'o}n de derechos de autor, alegando que la tecnolog{\'i}a de inteligencia artificial de las empresas copi{\'o} ilegalmente millones de art{\'i}culos del peri{\'o}dico para entrenar a ChatGPT y otros servicios para proporcionar informaci{\'o}n a las personas, tecnolog{\'i}a que ahora compite con la publicaci{\'o}n.},
  langid = {spanish},
  file = {/home/george/Zotero/storage/JCZKKVEL/the-new-york-times-demanda-a-openai-microsoft-infraccion-inteligencia-artificial-trax.html}
}

@misc{munoz-ledoOpenAIAfirmaQue2024,
  title = {{OpenAI afirma que la demanda de The New York Times por derechos de autor "no tiene fundamento"}},
  author = {{Mu{\~n}oz-Ledo}, Roc{\'i}o},
  year = {2024},
  month = jan,
  journal = {CNN},
  urldate = {2024-01-14},
  abstract = {OpenAI se opuso este lunes a la demanda presentada el mes pasado por The New York Times, que afirma que el gigante de la inteligencia artificial viol{\'o} la ley de derechos de autor al utilizar el periodismo del NYTimes para entrenar sus sistemas.},
  langid = {spanish},
  file = {/home/george/Zotero/storage/LY55PFY5/openai-demanda-the-new-york-times-derechos-autor-trax.html}
}


